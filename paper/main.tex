\documentclass[runningheads]{llncs}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{booktabs}
\begin{document}

\title{Predicción de crimen con Machine Learning usando datos espaciotemporales
de la región del Callao}

\titlerunning{Predicción de riesgo con ML}
\author{Juan Carlos Molero Rojas}

\authorrunning{J. Molero}
\institute{Universidad Tecnológica del Perú}

\maketitle

\begin{abstract}

La seguridad ciudadana representa uno de los desafíos más críticos en América
Latina, afectando directamente la calidad de vida y la confianza institucional.
Este estudio propone un modelo de aprendizaje automático para la predicción de
riesgo delictivo espaciotemporal en la región del Callao, Perú. Utilizando un
conjunto de datos de 2643 registros delictivos, se implementó una metodología
que integra el algoritmo DBSCAN para la identificación de zonas de alta
densidad y la evaluación comparativa de cinco algoritmos de
clasificación: Random Forest, K-Nearest Neighbors (KNN), Regresión Logística,
Support Vector Machine (SVM) y Gradient Boosting. Los resultados demostraron
que el modelo Gradient Boosting superó a los demás algoritmos, alcanzando una
exactitud global del 90.6\% y el mejor equilibrio (F1-Score de 0.61) en la
detección de la clase minoritaria de alto riesgo. Se concluye que el enfoque
propuesto, basado en el aprendizaje secuencial y el manejo del desbalance de
clases, ofrece una herramienta robusta para la emisión de alertas de seguridad
en tiempo real.

\keywords{Machine Learning \and Crime prediction \and Latitude \and
Longitude \and Spatiotemporal.}

\end{abstract}

\section{Introducción}

La seguridad ciudadana se ha transformado en uno de los retos sociales más
importantes en América Latina, que afectan de forma directa la calidad de vida
y el bienestar común. Este concepto incluye no solamente la protección contra
el delito, sino también la seguridad de derechos, la coexistencia pacífica y la
fe en las instituciones. Hoy en día, el aumento de delitos como la violencia
entre personas, el hurto y el crimen organizado han producido una sensación
generalizada de inseguridad, sobre todo en áreas urbanas en situación de
vulnerabilidad.

En el año 2020, un estudio realizado en el marco del proyecto CITYCoP encuestó
a 272 ciudadanos de 11 países europeos, revelando que el 16.2\% de los
participantes percibían vivir en zonas de alta criminalidad, mientras que el
68.8\% afirmaban lo contrario y un 15.1\% no estaban seguros. Aquellos que se
sentían expuestos a altos niveles de criminalidad reportaron un 58\% más de
signos de desorden social y físico en sus barrios, como edificios abandonados,
basura en las calles y actos de vandalismo. Además, presentaron un 37\% menos
de confianza en la policía y un 25\% menos de cohesión comunitaria en
comparación con quienes vivían en zonas consideradas seguras. Estos datos
evidencian que la percepción de inseguridad no solo afecta el bienestar
psicológico de los ciudadanos, sino que también deteriora la confianza
institucional y el tejido social \cite{reid2020}.

En Colombia, la seguridad ciudadana enfrenta una crisis persistente que se
refleja en cifras alarmantes. Solo en el año 2022 se registraron 13,536
homicidios intencionales, lo que equivale a un promedio de 37 muertes violentas
por día. Esta situación afecta a jóvenes y adultos entre los 19 y 59 años,
quienes representan más del 89\% de las víctimas. Asimismo, el hurto a personas
aumentó un 25.4\% respecto al año 2021, alcanzando más de 351,000 casos,
consolidándose como uno de los delitos de mayor crecimiento en la última
década. Con estas cifras se descubren patrones estructurales vinculados a la
informalidad laboral, la pobreza y la limitada presencia institucional en zonas
rurales \cite{nunez2024}.

En el ámbito nacional, la inseguridad ciudadana se ha consolidado como uno de
los principales desafíos sociales, con una percepción negativa que afecta a
múltiples regiones del Perú. Según una revisión sistemática de literatura de 15
estudios realizados entre 2020 y 2024, más del 73\% de los ciudadanos en zonas
como Chiclayo consideran ineficaces las intervenciones policiales, mientras que
en distritos como San Martín de Porres se reporta una falta de efectivos y
demoras considerables en la atención de denuncias. Esta situación se agrava por
factores estructurales como el desempleo juvenil, la informalidad económica, la
corrupción institucional y la migración venezolana, que han intensificado el
temor y la desconfianza hacia las autoridades. La inseguridad no solo deteriora
la calidad de vida, sino que también genera efectos psicológicos y sociales que
afectan la salud mental \cite{anton-chunga2025}.

\section{Trabajos relacionados}

La investigación sobre patrones delictivos es un aspecto importante para la
seguridad pública y, debido al avance de la inteligencia artificial, los
modelos de machine learning son una herramienta excelente para poder investigar
y contener el delito. El objetivo de este estudio es predecir los casos de
delincuencia de 2017 a 2020 utilizando un conjunto de datos de 2001 a 2016,
mediante la creación de modelos predictivos que anticipen futuras tendencias
delictivas. La metodología se basa en un modelo de machine learning que utiliza
algoritmos tanto de clasificación, agrupación y regresión, como lo son los
algoritmos de Regresión Lineal y Random Forest, aplicados a datos de delitos de
la India entre 2001 y 2016. Los resultados muestran una alta precisión en la
predicción de diversos tipos de delitos, con tasas de exactitud que van desde
el 89\% en intentos de asesinato hasta el 95\% en casos de violación y robo. En
conclusión, los modelos de machine learning, en particular el de K-Nearest
Neighbors, demuestran ser eficaces para predecir delitos con la precisión
deseada, identificando y localizando las zonas de mayor incidencia
\cite{s2024}.

Asimismo, dada la alta percepción de inseguridad en Perú, y en particular en el
distrito limeño de Los Olivos que se ha convertido en un problema nacional,
surge esta investigación. El objetivo del estudio fue proponer una solución
tecnológica para la seguridad ciudadana y la prevención del delito, capaz de
enviar una alerta en tiempo real a los usuarios indicando la probabilidad de
que ocurra un acto delictivo en su ubicación. La metodología se basó en el
desarrollo de un modelo de machine learning utilizando el algoritmo Naive
Bayes, el cual fue validado comparando su rendimiento con otros algoritmos como
Classification Forest, Catboost y KNN a través de una matriz de confusión y
métricas como accuracy, precision y recall, además de ser probado con una
muestra de 108 usuarios. Los resultados de la validación con usuarios arrojaron
un alto nivel de aceptación, con un 93.5\% de ellos indicando que la solución
ayuda a prevenir incidentes delictivos. En la validación técnica, aunque el
artículo no especifica los porcentajes exactos de las métricas, según menciona
el autor, se determinó que Naive Bayes fue el más adecuado porque a pesar de
tener un valor de accuracy similar al de otros modelos, ofrecía la mejor
distribución de variables por categoría y una mayor velocidad de predicción. En
conclusión, el proyecto logró desarrollar una solución tecnológica funcional
para la prevención del delito, demostrando la eficacia del algoritmo Naive
Bayes y obteniendo una alta aceptación por parte de los usuarios
\cite{mansilla2023}.

En \cite{ahmad2024} los autores mencionan la importancia de entender los
patrones de los registros delictivos para poder prevenir tipos de crímenes que
vienen desde hurto y vandalismo hasta homicidios y terrorismo. El objetivo de
su investigación fue crear un dashboard basado en datos espacio temporales para
predecir puntos críticos en las ciudades de tal manera que sea posible realizar
un seguimiento en tiempo real. Los autores llamaron CHART a la metodología
utilizada durante su investigación, este consiste en el uso de los datasets
"Crime in Vancouver" de Kaggle con 530 652 registros desde 2006 al 2021, "ICT
Police Crime Data" de la base de datos policial ICT con 120 442 registros desde
2009 al 2021 y "Crime in India" con 530,652 registros, seguido del
preprocesamiento de los datos através de la normalización y asegurando
consistencia en las 3 fuentes de datos; continuando con el balance de los datos
con Adaptive Synthetic Sampling (ADASYN); seguido de el proceso de ingeniería
de características para extraer características importantes, etiquetarlas y
clasificarlas; como últimos pasos, los autores optaron por hacer un mapa de
calor para tener una visualización de los registros delictivos y la aplicación
de el modelo Random Forest para fines predictivos y preventivos. Como
resultado, la metodología utilizada en el estudio obtuvo un 95.65\% de
accuracy, 93.87\% de precisión y un 94.56\% de recall, logrando hacer una
diferencia significativa con las metodologías tradicionales que usan modelos
como KNN, Linear Regression, Logistic Regression, Support Vector Machine y
Naive Bayes. En conclusión, este estudio permite poder reforzar la seguridad
enfocándose en zonas con alto riesgo gracias a la visualización del mapa de
calor y prevenir incidentes mediante el modelo de machine predictivo.

\section{Metodología}

\begin{figure}[h!] 
    \centering 
    \includegraphics[width=1\textwidth]{diagrams/metodologia.png}
    \caption{Metodología}
\end{figure}


\subsection{Obtención del dataset}

Para este estudio, se utilizó el conjunto de datos de acceso público "Registros
delictivos del Observatorio Regional de Seguridad Ciudadana en la Provincia
Constitucional del Callao". Este dataset contiene un total de 2643 registros de
incidentes reportados.

Cada registro detalla información relevante sobre la denuncia, incluyendo la
ubicación geográfica, la marca temporal y la naturaleza del incidente. Las
columnas clave utilizadas para este análisis se describen en la tabla
\ref{tab:campos-dataset-completos}.

\begin{table}[h!]
\centering
\caption{Campos del dataset "Registros delictivos del Observatorio Regional de Seguridad Ciudadana en la Provincia Constitucional del Callao"}
\label{tab:campos-dataset-completos}
\resizebox{\textwidth}{!}{%
\begin{tabular}{l p{10cm}}
\toprule
\textbf{Campo} & \textbf{Descripción} \\
\midrule
\texttt{FECHA\_CORTE} & Fecha de corte de la extracción de datos. \\
\texttt{FECHA\_REGISTRO} & Fecha en que se registró la denuncia. \\
\texttt{ID\_DOC\_DENUNCIA} & Identificador único del documento de denuncia. \\
\texttt{UBIGEO} & Código de Ubicación Geográfica (Ubigeo). \\
\texttt{DEPARTAMENTO} & Departamento donde ocurrió el hecho. \\
\texttt{PROVINCIA} & Provincia donde ocurrió el hecho. \\
\texttt{DISTRITO} & Distrito donde ocurrió el hecho. \\
\texttt{TIPO\_DE\_DENUNCIA} & Tipo de documento (ej. "DENUNCIA"). \\
\texttt{SITUACION\_DENUNCIA} & Estado actual de la denuncia (ej. "PENDIENTE"). \\
\texttt{TIPO} & Categoría principal del incidente (ej. "PATRIMONIO"). \\
\texttt{SUBTIPO} & Subcategoría del incidente. \\
\texttt{MODALIDAD} & Modalidad específica del incidente. \\
\texttt{FECHA\_HECHO} & Fecha en la que ocurrió el incidente. \\
\texttt{HORA\_HECHO} & Hora (en formato entero) del incidente. \\
\texttt{UBICACION} & Dirección o lugar de referencia del incidente. \\
\texttt{DESCRIPCION} & Descripción de la ubicación. \\
\texttt{FECHA\_NACIMIENTO} & Fecha de nacimiento del denunciante/víctima. \\
\texttt{EDAD\_PERSONA} & Edad del denunciante/víctima. \\
\texttt{SEXO} & Sexo del denunciante/víctima. \\
\texttt{ESTADO\_CIVIL} & Estado civil del denunciante/víctima. \\
\texttt{GRADO\_INSTRUCCION} & Grado de instrucción del denunciante/víctima. \\
\texttt{OCUPACION} & Ocupación del denunciante/víctima. \\
\texttt{PAIS\_NATAL} & País de nacimiento del denunciante/víctima. \\
\texttt{MES} & Mes en que ocurrió el hecho. \\
\texttt{LONGITUD} & Coordenada de longitud (geográfica). \\
\texttt{LATITUD} & Coordenada de latitud (geográfica). \\
\bottomrule
\end{tabular}
}
\end{table}

\begin{figure}[h!] 
    \centering 
    \includegraphics[width=1\textwidth]{diagrams/incidentes.png}
    \caption{Número de incidentes por hora}
\end{figure}

\begin{figure}[h!] 
    \centering 
    \includegraphics[width=1\textwidth]{diagrams/incidentes_dia.png}
    \caption{Número de incidentes por cada día de la semana}
\end{figure}

\subsection{Preprocesamiento}

El dataset crudo no es directamente aplicable a un modelo de predicción de
riesgo. Por lo tanto, se implementó un pipeline de preprocesamiento para
transformar los registros de incidentes en un formato de (Zona, Día de la
semana, Hora)
$\rightarrow$ Riesgo.

\subsubsection{DBSCAN}

Para definir "zonas" o "hotspots" de riesgo de manera automática, se aplicó el
algoritmo DBSCAN (Density-Based Spatial Clustering of Applications with Noise).
Este método se aplicó sobre las coordenadas (LONGITUD, LATITUD) escaladas y
permitió agrupar los incidentes en clusters de alta densidad, asignando a cada
uno un CLUSTER\_ID. Los incidentes aislados (ruido, cluster -1) fueron
descartados del análisis posterior.

\begin{figure}[h!] 
    \centering 
    \includegraphics[width=1\textwidth]{diagrams/cluster_dbscan.png}
    \caption{Mapa de clusters de riesgo generado por DBSCAN}
\end{figure}

\subsubsection{Generación del Dataset de Entrenamiento}

Se generó un nuevo dataset donde la unidad de análisis no es el incidente, sino
el bloque (Zona, Hora). Se crearon todas las combinaciones posibles de
CLUSTER\_ID (zonas) y HORA\_DEL\_DIA (0-23). Posteriormente, se contabilizó el
número de incidentes (NRO\_INCIDENTES) para cada bloque.

\subsubsection{Codificación de Variables}

la variable objetivo NIVEL\_RIESGO se creó mediante la discretización de
NRO\_INCIDENTES en tres categorías: 'Bajo' (0 incidentes) y 'Alto'
(definidos por la mediana de los bloques con incidentes). Las variables
predictoras (CLUSTER\_ID y HORA\_DEL\_DIA) fueron transformadas usando One-Hot
Encoding para su uso en los modelos.

\subsection{Implementación de los modelos}

Para la tarea de clasificación multiclase (Bajo, Alto), se seleccionaron
y evaluaron dos modelos con diferentes enfoques algorítmicos. Los datos se
dividieron en conjuntos de entrenamiento (80\%) y prueba (20\%) utilizando
estratificación para mantener la proporción de las clases.

\subsubsection{Random Forest}

Se implementó un Random Forest Classifier, un modelo de ensamblaje (ensemble)
basado en árboles de decisión. Este método opera construyendo múltiples árboles
de decisión durante el entrenamiento y emitiendo la clase que es la moda de las
clases de los árboles individuales \cite{breiman2001}. Se utilizó el
parámetro class\_weight='balanced' para mitigar el desbalanceo de clases
inherente al dataset.

\begin{equation}
    \hat{y} = c_{\text{argmax}} \sum_{t=1}^{T} \mathbb{I}(h_t(x) = c)
\end{equation}

Donde:
\begin{itemize}
    \item $\hat{y}$: La clase predicha final por el modelo (moda de las predicciones).
    \item $T$: Número total de árboles de decisión en el bosque ($n\_estimators$).
    \item $h_t(x)$: Predicción de la clase realizada por el $t$-ésimo árbol individual para la entrada $x$.
    \item $\mathbb{I}(\cdot)$: Función indicadora que retorna 1 si la condición es verdadera y 0 en caso contrario.
\end{itemize}

\subsubsection{K-Nearest Neighbors}

Se implementó un clasificador K-Nearest Neighbors (KNN). Este es un modelo no
paramétrico basado en instancia que clasifica un punto de datos (un bloque
Zona-Hora) según la clase mayoritaria de sus 'k' vecinos más cercanos en el
espacio de características codificado \cite{cover1967}. Para este estudio, se utilizó un valor
de k=7.

Distancia Euclidiana:

\begin{equation}
    d(x, x_i) = \sqrt{\sum_{j=1}^{p} (x_j - x_{ij})^2}
\end{equation}

Función de decisión:

\begin{equation}
    P(y = c | x) = \frac{1}{k} \sum_{i \in N_k(x)} \mathbb{I}(y_i = c)
\end{equation}

Donde:
\begin{itemize}
    \item $P(y = c | x)$: Probabilidad estimada de que el punto $x$ pertenezca a la clase $c$.
    \item $k$: Número de vecinos más cercanos considerados (hiperparámetro).
    \item $N_k(x)$: Conjunto de índices de los $k$ puntos de entrenamiento más cercanos a $x$ según la distancia Euclidiana.
    \item $y_i$: Etiqueta de clase real del vecino $i$-ésimo.
    \item $\mathbb{I}(y_i = c)$: Función que vale 1 si el vecino $i$ pertenece a la clase $c$, y 0 si no.
\end{itemize}

\subsubsection{Logistic Regression}

Se incluyó la Regresión Logística como modelo de referencia (baseline). Este es
un algoritmo estadístico lineal que estima la probabilidad de que una instancia
pertenezca a una clase determinada utilizando la función logística. Su
inclusión permite evaluar si las relaciones entre las variables predictoras
(zona, hora, día) y el nivel de riesgo son linealmente separables
\cite{hosmer2013}. Al igual que en los modelos anteriores, se configuró
el parámetro \texttt{class\_weight='balanced'} para ajustar los pesos de las
clases inversamente proporcionales a sus frecuencias.

\begin{equation}
    P(y=1 | x) = \sigma(w^T x + b) = \frac{1}{1 + e^{-(w^T x + b)}}
\end{equation}

Donde:
\begin{itemize}
    \item $P(y=1 | x)$: Probabilidad condicional de que la instancia pertenezca a la clase positiva (Riesgo Alto).
    \item $\sigma(z)$: Función sigmoide logística definida como $\frac{1}{1+e^{-z}}$.
    \item $w$: Vector de pesos o coeficientes aprendidos por el modelo asociados a las características.
    \item $x$: Vector de características de entrada (zona, día, hora).
    \item $b$: Término de sesgo (\textit{bias}) o intercepto.
\end{itemize}

\subsubsection{Support Vector Machine (SVM)}

Se evaluó el algoritmo de Máquinas de Vectores de Soporte (SVM). Este modelo
supervisado busca encontrar el hiperplano óptimo que maximice el margen de
separación entre las clases en un espacio multidimensional. Para este estudio,
se utilizó un kernel de Función de Base Radial (\texttt{kernel='rbf'}), lo que
permite al modelo proyectar los datos a una dimensión superior y manejar
fronteras de decisión no lineales \cite{cortes1995}. Se mantuvo el balanceo de pesos para
contrarrestar la desproporción de los datos.

Kernel RBF:

\begin{equation}
    K(x, x_i) = \exp\left(-\gamma ||x - x_i||^2\right)
\end{equation}

Donde:
\begin{itemize}
    \item $K(x, x_i)$: Función Kernel (RBF) que calcula la similitud en un espacio dimensional superior.
    \item $\gamma$: Parámetro del kernel que define el alcance de la influencia de un solo ejemplo de entrenamiento.
    \item $b$: Término de sesgo del hiperplano óptimo.
\end{itemize}

\subsubsection{Gradient Boosting Classifier}

Finalmente, se implementó el clasificador Gradient Boosting. A diferencia del
Random Forest que utiliza la técnica de \textit{bagging} (paralelo), este es un
método de ensamblaje basado en \textit{boosting} (secuencial). El algoritmo
construye una serie de árboles de decisión de forma iterativa, donde cada nuevo
árbol se enfoca en corregir los errores residuales cometidos por el conjunto de
árboles anteriores \cite{friedman2001}. Se configuró con 100 estimadores, permitiendo al modelo
aprender patrones complejos y refinar la precisión en las instancias difíciles
de clasificar.

\begin{equation}
    F_M(x) = \sum_{m=1}^{M} \nu \cdot h_m(x)
\end{equation}

Donde:
\begin{itemize}
    \item $F_M(x)$: Predicción final del ensamblaje tras completar $M$ etapas.
    \item $M$: Número total de iteraciones o árboles construidos.
    \item $\nu$: Tasa de aprendizaje (\textit{learning rate}) que escala la contribución de cada nuevo árbol ($0 < \nu \leq 1$).
    \item $h_m(x)$: Árbol de decisión base (\textit{weak learner}) entrenado para predecir el pseudo-residuo (error) de la etapa anterior $F_{m-1}(x)$.
\end{itemize}

\subsection{Evaluación de métricas}

Para evaluar el rendimiento de los modelos predictivos, se utilizaron métricas
estándar derivadas de la matriz de confusión \cite{powers2011}.

\subsubsection{Accuracy}

La exactitud (Accuracy) mide la proporción total de predicciones correctas
(tanto positivas como negativas) sobre el total de casos evaluados. Es una
métrica global del desempeño del modelo.

\begin{equation}
    \text{Accuracy} = \frac{TP + TN}{TP + TN + FP + FN}
\end{equation}

\subsubsection{Precision}

La precisión evalúa la calidad de las predicciones positivas. Indica qué
proporción de las instancias clasificadas como "Alto Riesgo" realmente
pertenecían a esa categoría, penalizando los falsos positivos.

\begin{equation}
    \text{Precision} = \frac{TP}{TP + FP}
\end{equation}

\subsubsection{Recall}

También conocido como Sensibilidad, mide la capacidad del modelo para
identificar correctamente todas las instancias positivas reales. En este
contexto, indica qué porcentaje de las zonas de riesgo real fueron detectadas
por el modelo.

\begin{equation}
    \text{Recall} = \frac{TP}{TP + FN}
\end{equation}

\subsubsection{ROC AUC}

El Área Bajo la Curva ROC (Receiver Operating Characteristic) evalúa la
capacidad del modelo para distinguir entre clases a través de diferentes
umbrales de decisión. La curva representa la relación entre la Tasa de
Verdaderos Positivos (TPR) y la Tasa de Falsos Positivos (FPR). Un valor de AUC
de 1 indica un modelo perfecto, mientras que 0.5 indica una clasificación
aleatoria.

\begin{equation}
    \text{TPR} = \frac{TP}{TP + FN}, \quad \text{FPR} = \frac{FP}{FP + TN}
\end{equation}

\subsubsection{F1 Score}

El F1 Score es la media la Precisión y el Recall. Es una métrica fundamental en
datasets desbalanceados, ya que penaliza a los modelos que tienen una precisión
alta pero un recall bajo o viceversa, proporcionando un balance único del
rendimiento en la clase positiva.

\begin{equation}
    F1 = 2 \cdot \frac{\text{Precision} \cdot \text{Recall}}{\text{Precision} + \text{Recall}}
\end{equation}

Donde:
\begin{itemize}
    \item TP: True Positives  
    \item TN: True Negatives  
    \item FP: False Positives 
    \item FN: False Negatives 
\end{itemize}

\section{Resultados}

Tras el entrenamiento y evaluación de los cinco algoritmos seleccionados
(Random Forest, KNN, Regresión Logística, SVM y Gradient Boosting) sobre el
conjunto de prueba, se obtuvieron métricas de desempeño que permiten determinar
la eficacia de cada modelo para la tarea de predicción de riesgo delictivo.

Modelos Base (KNN, Regresión Logística, SVM) mostraron un desempeño inferior en
la identificación de patrones complejos. Aunque SVM y Regresión Logística
obtuvieron un Recall aceptable, su precisión fue baja, lo que indica una
tendencia a generar un exceso de falsas alarmas, reduciendo la confiabilidad
del sistema.

Por otro lado, los modelos de Ensamble (Random Forest y Gradient Boosting)
dominaron la comparativa, alcanzando una exactitud global superior al 90\%. Sin
embargo, se observó una competencia ajustada en la capacidad de generalización
sobre la clase positiva.

Debido a esto, el Gradient Boosting Classifier demostró ser el algoritmo con
mejor rendimiento general, superando marginalmente al Random Forest en el
F1-Score para la clase de "Alto Riesgo" (0.6095 frente a 0.6086) y presentando
el mejor equilibrio entre Precisión y Recall como se puede percibir en la tabla
\ref{tab:rendimiento-modelos}.

\begin{table}[h!]
\centering
\caption{Rendimiento de los Modelos de Clasificación}
\label{tab:rendimiento-modelos}
\begin{tabular}{l c c c}
\toprule
\textbf{Modelo} & \textbf{Accuracy} & \textbf{F1-Score} & \textbf{Recall} \\
\midrule
Gradient Boosting & 0.906178 & 0.609524 & 0.453901 \\
Random Forest & 0.907323 & 0.608696 & 0.446809 \\
SVM (Kernel RBF) & 0.845538 & 0.532872 & 0.546099 \\
Logistic Regression & 0.815789 & 0.504615 & 0.581560 \\
KNN (k=7) & 0.882151 & 0.477157 & 0.333333 \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[h!] 
    \centering 
    \label{fig:matriz_confusion}
    \includegraphics[width=0.8\textwidth]{diagrams/matriz_confusion.png}
    \caption{Matriz de confusión de el modelo entrenado con Gradient Boosting}
\end{figure}

La Figura \ref{fig:matriz_confusion} presenta la matriz de confusión resultante
del modelo seleccionado sobre el conjunto de prueba.

Se observa una concentración significativa de aciertos en el cuadrante superior
izquierdo (Clase Real: Bajo / Predicción: Bajo). Esto confirma que el modelo ha
aprendido a identificar con una precisión casi perfecta las zonas y horarios
donde no existe riesgo delictivo.
    
El cuadrante inferior izquierdo (Clase Real: Bajo / Predicción: Alto) presenta
valores cercanos a cero. Esto indica que el sistema es altamente confiable
cuando emite una alerta; es decir, prácticamente no genera "falsas alarmas".
    
Respecto a la clase minoritaria ("Alto"), se aprecia una dispersión entre
aciertos. El modelo adopta un enfoque conservador: prioriza asegurar que una
alerta sea real antes que intentar capturar todos los eventos posibles a costa
de generar ruido. Aunque esto implica que algunas zonas de riesgo podrían no
ser etiquetadas como tales, garantiza que las zonas marcadas como peligrosas
posean una probabilidad de incidencia delictiva verificada y alta.

\section{Discusión}

Los resultados obtenidos validan la tendencia observada en la literatura
reciente sobre la superioridad de los modelos de ensamble para la predicción
delictiva. En concordancia con \cite{ahmad2024}, nuestra
experimentación confirmó que algoritmos como Gradient Boosting y Random Forest
superan significativamente a modelos tradicionales (KNN, SVM) en el manejo de
datos complejos y desbalanceados. Asimismo, a diferencia del enfoque local de
 \cite{mansilla2023}, quien priorizó la velocidad de procesamiento
utilizando Naive Bayes, esta investigación se centró en maximizar la métrica
F1-Score para la detección de la clase minoritaria ("Alto Riesgo").

Aunque los resultados obtenidos con el modelo Gradient Boosting son
prometedores para la identificación de zonas de alto riesgo, es necesario
reconocer ciertas limitaciones al diseño del estudio. En primer lugar, el
modelo fue entrenado utilizando exclusivamente denuncias formales, lo que
excluye la criminalidad que nunca fue reportada y podría subestimar el riesgo
en zonas con baja tasa de denuncia. Asimismo, se optó por una clasificación
binaria (Seguro/Riesgo) tras evidenciarse durante la experimentación que una
escala de tres niveles introducía ruido estadístico significativo entre las
categorías intermedia y baja; esta decisión, aunque necesaria para garantizar
la confiabilidad operativa, limita la efectividad de las predicciones.

\bibliographystyle{splncs04}
\bibliography{ref}

\end{document}
